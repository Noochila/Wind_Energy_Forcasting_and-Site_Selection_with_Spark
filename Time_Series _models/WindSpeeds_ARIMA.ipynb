{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import TimestampType\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"TimeSeriesForecasting\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into a Spark DataFrame\n",
    "df = spark.read.csv(\"T1.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Preprocess data\n",
    "dataset = df.select(\"Date/Time\", \"Wind Speed (m/s)\") \\\n",
    "            .withColumnRenamed(\"Date/Time\", \"timeStamp\") \\\n",
    "            .withColumnRenamed(\"Wind Speed (m/s)\", \"windSpeed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timeStamp to datetime\n",
    "dataset = dataset.withColumn(\"timeStamp\", col(\"timeStamp\").cast(TimestampType()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check stationarity (Augmented Dickey-Fuller test)\n",
    "def adfuller_test(timeseries):\n",
    "    result = adfuller(timeseries)\n",
    "    print(\"ADF Statistic:\", result[0])\n",
    "    print(\"p-value:\", result[1])\n",
    "    print(\"Critical Values:\")\n",
    "    for key, value in result[4].items():\n",
    "        print(f\"\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Spark DataFrame to Pandas DataFrame for statistical tests\n",
    "pandas_df = dataset.toPandas()\n",
    "wind_speed_series = pandas_df[\"windSpeed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Augmented Dickey-Fuller test\n",
    "adfuller_test(wind_speed_series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the time series\n",
    "pandas_df.set_index(\"timeStamp\", inplace=True)\n",
    "pandas_df.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARIMA modeling\n",
    "model = ARIMA(wind_speed_series, order=(5,1,0))\n",
    "model_fit = model.fit()\n",
    "print(model_fit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecasting\n",
    "forecast = model_fit.forecast(steps=24)\n",
    "print(\"Forecasted values for the next 24 time steps:\")\n",
    "print(forecast)\n",
    "\n",
    "# Stop SparkSession\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
